---
phase: 06-chat-evaluation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - web_frontend/src/components/ChatMarkdown.tsx
  - web_frontend/src/components/module/NarrativeChatSection.tsx
  - core/promptlab/__init__.py
  - core/promptlab/fixtures.py
  - core/promptlab/fixtures/cognitive-superpowers-chat-1.json
  - core/promptlab/fixtures/cognitive-superpowers-chat-2.json
autonomous: true

must_haves:
  truths:
    - "ChatMarkdown is importable from @/components/ChatMarkdown"
    - "NarrativeChatSection still renders chat messages correctly after extraction"
    - "core.promptlab.fixtures.list_fixtures() returns fixture metadata"
    - "core.promptlab.fixtures.load_fixture(name) returns full fixture data"
    - "At least 2 fixture JSON files exist with valid schema"
  artifacts:
    - path: "web_frontend/src/components/ChatMarkdown.tsx"
      provides: "Shared markdown renderer for chat messages"
      exports: ["ChatMarkdown"]
    - path: "core/promptlab/__init__.py"
      provides: "Module exports for promptlab"
    - path: "core/promptlab/fixtures.py"
      provides: "Fixture listing and loading"
      exports: ["list_fixtures", "load_fixture"]
    - path: "core/promptlab/fixtures/cognitive-superpowers-chat-1.json"
      provides: "Sample chat fixture"
  key_links:
    - from: "web_frontend/src/components/module/NarrativeChatSection.tsx"
      to: "web_frontend/src/components/ChatMarkdown.tsx"
      via: "import"
      pattern: "import.*ChatMarkdown.*from.*@/components/ChatMarkdown"
    - from: "core/promptlab/fixtures.py"
      to: "core/promptlab/fixtures/*.json"
      via: "pathlib glob"
      pattern: "FIXTURES_DIR.*glob"
---

<objective>
Extract ChatMarkdown to a shared component and create the core/promptlab/ backend module with fixture loading.

Purpose: Establish the two foundation pieces that all subsequent plans depend on -- a reusable chat markdown renderer for the Prompt Lab frontend, and the backend fixture infrastructure for loading curated conversation data.

Output: Shared ChatMarkdown component, core/promptlab/ Python module with fixture loading, 2 sample fixture JSON files.
</objective>

<execution_context>
@/home/penguin/.claude/get-shit-done/workflows/execute-plan.md
@/home/penguin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-chat-evaluation/06-CONTEXT.md
@.planning/phases/06-chat-evaluation/06-RESEARCH.md

@web_frontend/src/components/module/NarrativeChatSection.tsx
@core/modules/llm.py
@core/modules/chat.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extract ChatMarkdown to shared component</name>
  <files>
    web_frontend/src/components/ChatMarkdown.tsx
    web_frontend/src/components/module/NarrativeChatSection.tsx
  </files>
  <action>
    Extract the `ChatMarkdown` function (lines 19-90 of NarrativeChatSection.tsx) into a new shared component at `web_frontend/src/components/ChatMarkdown.tsx`.

    The new file should:
    - Export `ChatMarkdown` as the default export
    - Import `ReactMarkdown` from "react-markdown" and `remarkGfm` from "remark-gfm"
    - Accept `{ children: string }` props (same interface as current)
    - Contain the exact same markup/classNames as the current implementation

    Update NarrativeChatSection.tsx to:
    - Remove the local ChatMarkdown function definition (lines 19-90)
    - Add import: `import ChatMarkdown from "@/components/ChatMarkdown";`
    - Keep all other code unchanged

    This is a pure extraction refactor -- no behavioral changes. The existing chat UI must render identically after this change.
  </action>
  <verify>
    Run `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run lint && npm run build` -- both must pass with no errors. Verify the import exists in NarrativeChatSection.tsx and the component exists in the new file.
  </verify>
  <done>
    ChatMarkdown is a standalone component at @/components/ChatMarkdown.tsx, imported by NarrativeChatSection.tsx, and the frontend builds without errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create core/promptlab/ module with fixture loading</name>
  <files>
    core/promptlab/__init__.py
    core/promptlab/fixtures.py
  </files>
  <action>
    Create the `core/promptlab/` Python package. Per user decision: Prompt Lab calls llm.py directly via core/promptlab/ -- does not modify chat.py or scoring.py (INFRA-03). Per user decision: does not write to any database tables (INFRA-04).

    1. Create `core/promptlab/__init__.py`:
       - Export `list_fixtures` and `load_fixture` from `.fixtures`
       - Module docstring explaining this is the Prompt Lab evaluation module

    2. Create `core/promptlab/fixtures.py`:
       - Define `FIXTURES_DIR = Path(__file__).parent / "fixtures"` constant
       - Define fixture schema type hints using TypedDict:
         ```python
         class FixtureSystemPrompt(TypedDict):
             base: str
             instructions: str

         class FixtureMessage(TypedDict):
             role: str  # "user" or "assistant"
             content: str

         class FixtureSummary(TypedDict):
             name: str
             module: str
             description: str

         class Fixture(TypedDict):
             name: str
             module: str
             description: str
             systemPrompt: FixtureSystemPrompt
             previousContent: str
             messages: list[FixtureMessage]
         ```
       - `def list_fixtures() -> list[FixtureSummary]`: Scan FIXTURES_DIR for *.json files using pathlib glob. For each file, load JSON and return list of `{name, module, description}` dicts. Sort by name. Return empty list if FIXTURES_DIR doesn't exist.
       - `def load_fixture(name: str) -> Fixture | None`: Load a specific fixture by name. Iterate JSON files in FIXTURES_DIR, find the one where the `name` field matches. Return the full fixture dict, or None if not found.
       - Both functions are synchronous (no async needed -- reading small local JSON files).
       - Handle JSON decode errors gracefully (skip malformed files, log warning with print).

    Do NOT import from core/modules/chat.py or core/modules/scoring.py. Do NOT import database modules.
  </action>
  <verify>
    Run `cd /home/penguin/code/lens-platform/ws2 && .venv/bin/python -c "from core.promptlab import list_fixtures, load_fixture; print('imports ok')"` -- must succeed.
    Run `cd /home/penguin/code/lens-platform/ws2 && ruff check core/promptlab/ && ruff format --check core/promptlab/` -- must pass.
  </verify>
  <done>
    core/promptlab/ module exists with list_fixtures() and load_fixture() functions, passes linting, and is importable.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create sample chat fixture JSON files</name>
  <files>
    core/promptlab/fixtures/cognitive-superpowers-chat-1.json
    core/promptlab/fixtures/cognitive-superpowers-chat-2.json
  </files>
  <action>
    Create the `core/promptlab/fixtures/` directory and populate it with 2 realistic sample chat fixture files. These are synthetic examples for development/testing -- real fixtures will be extracted from production data later via Claude Code.

    Per user decision: Fixtures stored as JSON in repo, not database (version-controlled, curated).

    Per the fixture schema from RESEARCH.md, each fixture must include:
    - `name`: Human-readable fixture name (e.g., "Cognitive Superpowers - Deceptive Alignment Discussion")
    - `module`: Module slug (e.g., "cognitive-superpowers")
    - `description`: Brief description of what this conversation covers
    - `systemPrompt`: Object with `base` (the hardcoded tutor prompt from chat.py) and `instructions` (the per-chat-stage instructions)
    - `previousContent`: String with the content the student just read/watched
    - `messages`: Array of `{role, content}` objects representing the conversation

    For the base system prompt, use the actual base prompt from `core/modules/chat.py` `_build_system_prompt()`:
    ```
    You are a tutor helping someone learn about AI safety. Each piece of content (article, video) has different topics and learning objectives.
    ```

    Fixture 1: "Cognitive Superpowers - Deceptive Alignment Discussion"
    - 4 messages (2 exchanges): student asks about deceptive alignment after reading an article, tutor responds, student asks follow-up, tutor elaborates
    - instructions: something about discussing deceptive alignment concepts
    - previousContent: 2-3 paragraphs of realistic AI safety article content about deceptive alignment

    Fixture 2: "Cognitive Superpowers - Instrumental Convergence"
    - 6 messages (3 exchanges): student discusses instrumental convergence, tutor guides understanding
    - instructions: something about exploring instrumental convergence
    - previousContent: 2-3 paragraphs about instrumental convergence

    Make the content realistic and substantive -- these are what facilitators will see when testing the Prompt Lab.

    After creating, verify the fixtures load correctly:
    ```python
    from core.promptlab import list_fixtures, load_fixture
    fixtures = list_fixtures()
    assert len(fixtures) == 2
    fixture = load_fixture(fixtures[0]["name"])
    assert fixture is not None
    assert "messages" in fixture
    ```
  </action>
  <verify>
    Run `cd /home/penguin/code/lens-platform/ws2 && .venv/bin/python -c "
from core.promptlab import list_fixtures, load_fixture
fixtures = list_fixtures()
print(f'Found {len(fixtures)} fixtures')
for f in fixtures:
    print(f'  - {f[\"name\"]} ({f[\"module\"]})')
    full = load_fixture(f['name'])
    assert full is not None, f'Failed to load {f[\"name\"]}'
    assert len(full['messages']) >= 4, f'Too few messages in {f[\"name\"]}'
    print(f'    {len(full[\"messages\"])} messages, has systemPrompt: {\"systemPrompt\" in full}')
print('All fixtures valid')
"` -- must print fixture details and "All fixtures valid".
  </verify>
  <done>
    2 fixture JSON files exist in core/promptlab/fixtures/, each with valid schema including name, module, description, systemPrompt, previousContent, and messages array. list_fixtures() returns both, load_fixture() loads each successfully.
  </done>
</task>

</tasks>

<verification>
1. `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run build` passes (ChatMarkdown extraction didn't break frontend)
2. `cd /home/penguin/code/lens-platform/ws2 && ruff check core/promptlab/` passes
3. `from core.promptlab import list_fixtures, load_fixture` imports successfully
4. `list_fixtures()` returns 2 fixtures with name, module, description
5. `load_fixture("Cognitive Superpowers - Deceptive Alignment Discussion")` returns full fixture with messages array
6. NarrativeChatSection.tsx imports ChatMarkdown from @/components/ChatMarkdown (not local definition)
</verification>

<success_criteria>
- ChatMarkdown is a shared component importable from @/components/ChatMarkdown
- NarrativeChatSection.tsx uses the shared ChatMarkdown (no local copy)
- Frontend builds and lints without errors
- core/promptlab/ module exists with fixture loading functions
- 2 sample fixture JSON files exist with valid schema
- Python linting passes for core/promptlab/
</success_criteria>

<output>
After completion, create `.planning/phases/06-chat-evaluation/06-01-SUMMARY.md`
</output>
