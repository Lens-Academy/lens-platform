---
phase: 06-chat-evaluation
plan: 04
type: execute
wave: 3
depends_on: ["06-02", "06-03"]
files_modified:
  - web_frontend/src/views/PromptLab.tsx
  - web_frontend/src/components/promptlab/PromptEditor.tsx
  - web_frontend/src/components/promptlab/ConversationPanel.tsx
autonomous: true

must_haves:
  truths:
    - "Facilitator sees two-panel layout: prompt editor on left, conversation on right"
    - "Facilitator can edit the system prompt in a monospace textarea"
    - "Facilitator can reset the system prompt to the original from the fixture"
    - "Facilitator can click any AI message to select it for regeneration"
    - "Messages after the selected point are visually dimmed/collapsed"
    - "Clicking Regenerate streams a new AI response via SSE in real time"
    - "After regeneration, original AI message appears collapsed/dimmed above the new response"
    - "Facilitator can expand the original message to compare"
    - "Regenerated messages have a Show reasoning toggle for chain-of-thought"
    - "Facilitator can type follow-up messages as the student after regeneration"
  artifacts:
    - path: "web_frontend/src/views/PromptLab.tsx"
      provides: "Main Prompt Lab view with two-panel layout and state management"
      exports: ["default"]
    - path: "web_frontend/src/components/promptlab/PromptEditor.tsx"
      provides: "Left panel: monospace prompt editor with reset"
      exports: ["default"]
    - path: "web_frontend/src/components/promptlab/ConversationPanel.tsx"
      provides: "Right panel: conversation display with selection, regeneration, comparison, CoT, follow-up input"
      exports: ["default"]
  key_links:
    - from: "web_frontend/src/views/PromptLab.tsx"
      to: "web_frontend/src/api/promptlab.ts"
      via: "regenerateResponse and continueConversation calls"
      pattern: "regenerateResponse|continueConversation"
    - from: "web_frontend/src/components/promptlab/ConversationPanel.tsx"
      to: "web_frontend/src/components/ChatMarkdown.tsx"
      via: "import for message rendering"
      pattern: "import.*ChatMarkdown"
    - from: "web_frontend/src/views/PromptLab.tsx"
      to: "web_frontend/src/components/promptlab/PromptEditor.tsx"
      via: "import and props"
      pattern: "import.*PromptEditor"
    - from: "web_frontend/src/views/PromptLab.tsx"
      to: "web_frontend/src/components/promptlab/ConversationPanel.tsx"
      via: "import and props"
      pattern: "import.*ConversationPanel"
---

<objective>
Build the complete Prompt Lab interactive UI: two-panel layout with prompt editor, conversation display, message selection, regeneration with SSE streaming, original/regenerated comparison, chain-of-thought display, and follow-up messaging.

Purpose: This is the core user experience -- the plan that makes the Prompt Lab functional. Facilitators can load a fixture, edit the system prompt, regenerate any AI message, compare results, inspect reasoning, and continue the conversation.

Output: Full PromptLab view, PromptEditor component, ConversationPanel component with all interactive features.
</objective>

<execution_context>
@/home/penguin/.claude/get-shit-done/workflows/execute-plan.md
@/home/penguin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-chat-evaluation/06-CONTEXT.md
@.planning/phases/06-chat-evaluation/06-RESEARCH.md
@.planning/phases/06-chat-evaluation/06-01-SUMMARY.md
@.planning/phases/06-chat-evaluation/06-02-SUMMARY.md
@.planning/phases/06-chat-evaluation/06-03-SUMMARY.md

@web_frontend/src/components/ChatMarkdown.tsx
@web_frontend/src/api/promptlab.ts
@web_frontend/src/components/promptlab/FixtureBrowser.tsx
@web_frontend/src/components/module/NarrativeChatSection.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PromptEditor and ConversationPanel components</name>
  <files>
    web_frontend/src/components/promptlab/PromptEditor.tsx
    web_frontend/src/components/promptlab/ConversationPanel.tsx
  </files>
  <action>
    Create the two panel components that make up the Prompt Lab workbench.

    **PromptEditor.tsx (left panel):**

    Per user decisions:
    - Monospace textarea/code editor for system prompt -- no syntax highlighting (it's natural language)
    - Single explicit "Regenerate" button (no auto-regenerate on prompt change)
    - Reset button to restore original system prompt from the fixture
    - No prompt versioning or saving -- this is a scratchpad for iteration

    Props:
    ```typescript
    interface PromptEditorProps {
      systemPrompt: string;
      originalSystemPrompt: string;
      onSystemPromptChange: (prompt: string) => void;
      onReset: () => void;
      isModified: boolean;  // true when systemPrompt !== originalSystemPrompt
    }
    ```

    Implementation:
    - Full-height panel with flex-col layout
    - Header: "System Prompt" label + Reset button (only enabled when isModified, shows "Reset to original" or similar)
    - Body: `<textarea>` element with:
      - `font-family: monospace` (via Tailwind `font-mono` class)
      - Full width/height of available space (`flex-1`, `w-full`, `resize-none`)
      - Comfortable padding (p-3 or p-4)
      - Subtle border (border-gray-200 or border-gray-300)
      - `value={systemPrompt}` controlled by parent
      - `onChange` calls `onSystemPromptChange`
    - No submit button here -- regeneration is triggered from the conversation panel via message selection
    - Show a subtle indicator when the prompt has been modified (e.g., small dot or "Modified" badge near the header)

    **ConversationPanel.tsx (right panel):**

    Per user decisions:
    - Reuse existing chat bubble pattern (student/tutor messages) via ChatMarkdown
    - Facilitator clicks any AI message to select it for regeneration
    - Messages after the selected point are dimmed/collapsed
    - After regeneration, original AI message appears collapsed/dimmed directly above the new response
    - Facilitator can expand the original to compare
    - Chain-of-thought: collapsible "Show reasoning" toggle below each regenerated message, collapsed by default
    - Only regenerated messages show comparison/CoT -- original messages stay clean
    - Follow-up text input at bottom (same pattern as student chat, minus voice recording)

    Props:
    ```typescript
    interface ConversationMessage {
      role: "user" | "assistant";
      content: string;
      isRegenerated?: boolean;
      originalContent?: string;     // Original AI response before regeneration
      thinkingContent?: string;     // Chain-of-thought for regenerated messages
    }

    interface ConversationPanelProps {
      messages: ConversationMessage[];
      selectedMessageIndex: number | null;  // Index of AI message selected for regeneration
      streamingContent: string;             // Currently streaming response text
      streamingThinking: string;            // Currently streaming thinking text
      isStreaming: boolean;
      onSelectMessage: (index: number) => void;
      onRegenerate: () => void;
      onSendFollowUp: (message: string) => void;
      canRegenerate: boolean;               // true when a message is selected
      canSendFollowUp: boolean;             // true after regeneration completes
    }
    ```

    Implementation:
    - Scrollable message list taking most of the panel height
    - Each message rendered as a chat bubble:
      - User messages: `bg-gray-100 text-gray-800 ml-8` with "Student" label (not "You" -- facilitator is observing)
      - Assistant messages: `bg-blue-50 text-gray-800` with "Tutor" label
      - Use ChatMarkdown for assistant message content
      - User messages rendered as plain text with `whitespace-pre-wrap`
    - **AI message selection:**
      - Assistant messages are clickable (cursor-pointer, hover highlight)
      - When clicked, `onSelectMessage(index)` is called
      - Selected message gets a visible highlight (e.g., ring-2 ring-blue-400 or border-blue-400)
      - Messages AFTER the selected index get `opacity-40` and a subtle "will be replaced" indicator
      - A "Regenerate" button appears near the selected message (or as a floating action)
    - **After regeneration (message.isRegenerated === true):**
      - Show the original message collapsed above the new one:
        - A small clickable bar: "Original response" with expand/collapse chevron
        - When expanded, show the original content in a dimmed/gray container (bg-gray-50, text-gray-500)
        - Collapsed by default
      - Show the regenerated content as the main message bubble
      - Below the regenerated message: "Show reasoning" toggle (if thinkingContent exists)
        - Collapsed by default
        - When expanded, show thinking content in a distinct container (bg-amber-50 or bg-yellow-50 with monospace text, slightly smaller font)
    - **Streaming state:**
      - While `isStreaming` and `streamingContent` is non-empty, render a streaming bubble at the appropriate position
      - Show "Thinking..." indicator if `streamingThinking` is non-empty (before text starts)
      - Use ChatMarkdown for streaming content
    - **Follow-up input:**
      - Text input at the bottom of the panel (textarea + Send button)
      - Similar to NarrativeChatSection's input but without voice recording
      - Only enabled when `canSendFollowUp` is true
      - On submit, calls `onSendFollowUp(message)`
      - Placeholder: "Send a follow-up message as the student..."
    - Auto-scroll to bottom when new content streams in
  </action>
  <verify>
    Run `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run lint` -- must pass.
    Run `cd /home/penguin/code/lens-platform/ws2/web_frontend && npx tsc --noEmit --pretty` -- must pass (type checking).
  </verify>
  <done>
    PromptEditor component renders monospace textarea with reset functionality. ConversationPanel component renders messages with selection, regeneration trigger, original/regenerated comparison, chain-of-thought toggle, streaming display, and follow-up input. Both lint and type-check cleanly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build complete PromptLab view with state management and streaming</name>
  <files>web_frontend/src/views/PromptLab.tsx</files>
  <action>
    Replace the placeholder PromptLab.tsx (from Plan 03) with the full implementation. This is the central state manager and layout component for the Prompt Lab.

    Per user decisions:
    - Two-panel layout: prompt editor on left, conversation on right (side-by-side, not stacked)
    - Flow: load fixture -> conversation on right -> edit prompt on left -> select message -> "Regenerate" -> new response streams in
    - Loading a fixture replaces the current conversation (no multi-tab)

    **State:**
    ```typescript
    // Fixture state
    const [fixture, setFixture] = useState<Fixture | null>(null);

    // Conversation state
    const [messages, setMessages] = useState<ConversationMessage[]>([]);

    // Prompt state
    const [systemPrompt, setSystemPrompt] = useState("");
    const [originalSystemPrompt, setOriginalSystemPrompt] = useState("");

    // Interaction state
    const [selectedMessageIndex, setSelectedMessageIndex] = useState<number | null>(null);
    const [isStreaming, setIsStreaming] = useState(false);
    const [streamingContent, setStreamingContent] = useState("");
    const [streamingThinking, setStreamingThinking] = useState("");
    const [hasRegenerated, setHasRegenerated] = useState(false);
    ```

    **Key behaviors:**

    1. **Loading a fixture** (callback from FixtureBrowser):
       - Set `fixture` state
       - Convert fixture.messages to ConversationMessage[] (no isRegenerated, no originalContent)
       - Assemble system prompt: combine `fixture.systemPrompt.base` + `\n\nInstructions:\n` + `fixture.systemPrompt.instructions` + (if previousContent exists) `\n\nThe user just engaged with this content:\n---\n` + `fixture.previousContent` + `\n---`
       - This mirrors the `_build_system_prompt()` logic from `core/modules/chat.py`
       - Set both `systemPrompt` and `originalSystemPrompt`
       - Reset all interaction state (selectedMessageIndex, isStreaming, etc.)

    2. **Selecting a message for regeneration:**
       - Only assistant messages are selectable
       - Set `selectedMessageIndex`
       - Reset `hasRegenerated` to false

    3. **Triggering regeneration** (when user clicks Regenerate):
       - Get messages up to (but not including) the selected message: `messages.slice(0, selectedMessageIndex)`
       - Call `regenerateResponse(messagesToSend, systemPrompt, true)` from the API client (enable thinking by default)
       - As events stream in:
         - `type: "thinking"` -> accumulate into `streamingThinking`
         - `type: "text"` -> accumulate into `streamingContent`
         - `type: "done"` -> finalize:
           - Create a new ConversationMessage with `isRegenerated: true`, `originalContent: messages[selectedMessageIndex].content`, `content: streamingContent`, `thinkingContent: streamingThinking`
           - Replace messages from `selectedMessageIndex` onward with just this new regenerated message
           - Clear streaming state, set `hasRegenerated = true`, clear selectedMessageIndex
         - `type: "error"` -> show error (could use a simple alert or inline error state)
       - During streaming, `isStreaming = true`

    4. **Sending a follow-up** (after regeneration):
       - Append the user message to messages array as `{role: "user", content: message}`
       - Call `continueConversation(allMessages, systemPrompt, true)` (enable thinking)
       - Stream the response same way as regeneration, but append the new assistant message at the end (not replacing anything)
       - The new assistant message should also be marked `isRegenerated: true` (it's a Prompt Lab generation, not original) with its own thinkingContent

    5. **Resetting the prompt:**
       - Set `systemPrompt` back to `originalSystemPrompt`

    **Layout:**
    ```
    <div className="h-[calc(100dvh-...)] flex">
      {fixture ? (
        <>
          <div className="w-1/2 border-r border-gray-200 flex flex-col">
            <PromptEditor ... />
          </div>
          <div className="w-1/2 flex flex-col">
            <ConversationPanel ... />
          </div>
        </>
      ) : (
        <FixtureBrowser onSelectFixture={handleLoadFixture} />
      )}
    </div>
    ```

    - When no fixture is loaded, show FixtureBrowser taking the full width
    - When a fixture is loaded, show the two-panel layout
    - Include a way to go back to fixture browser (e.g., a "Change fixture" button in the header area or breadcrumb)
    - Auth check: if not authenticated, redirect to login using `useAuth().login()`. If loading, show spinner.

    **Auth gate:** Check `useAuth()` at the top of the component. If `isLoading`, show a loading state. If not `isAuthenticated`, call `login()` to redirect. This ensures only logged-in users reach the Prompt Lab (the API will additionally enforce facilitator role).

    **Header area** (above the two panels): Show fixture name and a "Change fixture" link/button. Keep it minimal -- one line.
  </action>
  <verify>
    Run `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run lint && npm run build` -- both must pass.
  </verify>
  <done>
    PromptLab view implements full two-panel layout with state management. Loading a fixture shows prompt editor (left) and conversation (right). Selecting an AI message and clicking Regenerate streams a new response via SSE. After regeneration, facilitator can compare original/new, view reasoning, and send follow-up messages. Frontend builds and lints without errors.
  </done>
</task>

</tasks>

<verification>
1. `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run build` passes
2. `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run lint` passes
3. PromptLab view renders two-panel layout when fixture is loaded
4. PromptEditor displays monospace textarea with system prompt
5. ConversationPanel renders messages with clickable AI messages
6. Messages after selection point are dimmed
7. Regeneration streams via SSE and displays inline
8. Original/regenerated comparison is available (collapsed by default)
9. Chain-of-thought toggle works on regenerated messages
10. Follow-up input allows sending messages as student
</verification>

<success_criteria>
- Two-panel layout renders correctly (prompt editor left, conversation right)
- System prompt is editable in monospace textarea with reset to original
- AI messages are clickable for selection, with visual highlighting
- Regeneration streams SSE events and displays text in real time
- After regeneration: original response shown collapsed above new response
- Chain-of-thought expandable on regenerated messages
- Follow-up messages can be sent as the student
- All streaming state management works (loading, streaming, complete, error)
- Auth gate prevents unauthenticated access
- Frontend builds clean (no TypeScript errors, no lint errors)
</success_criteria>

<output>
After completion, create `.planning/phases/06-chat-evaluation/06-04-SUMMARY.md`
</output>
