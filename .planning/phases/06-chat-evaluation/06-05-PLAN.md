---
phase: 06-chat-evaluation
plan: 05
type: execute
wave: 4
depends_on: ["06-04"]
files_modified: []
autonomous: false

must_haves:
  truths:
    - "Full Prompt Lab workflow works end-to-end: load fixture, edit prompt, regenerate, compare, continue"
    - "Non-facilitator users cannot access /promptlab or API endpoints"
    - "SSE streaming displays text progressively without buffering delays"
  artifacts: []
  key_links: []
---

<objective>
Verify the complete Prompt Lab works end-to-end with a live facilitator session.

Purpose: Confirm all pieces integrate correctly -- auth gating, fixture loading, prompt editing, SSE streaming, comparison, chain-of-thought, and follow-up messaging -- in a real browser session.

Output: Verified working Prompt Lab with any integration issues fixed.
</objective>

<execution_context>
@/home/penguin/.claude/get-shit-done/workflows/execute-plan.md
@/home/penguin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-chat-evaluation/06-CONTEXT.md
@.planning/phases/06-chat-evaluation/06-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Start dev servers and run automated checks</name>
  <files></files>
  <action>
    Start the backend and frontend dev servers, then run a series of automated checks to verify the integration before manual testing.

    1. Start backend: `cd /home/penguin/code/lens-platform/ws2 && python main.py --dev --no-bot` (in background)
    2. Start frontend: `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run dev -- --host` (in background)
    3. Wait for both to be ready

    Run automated checks using curl:

    a. **Auth gate (unauthenticated):**
       `curl -s -o /dev/null -w "%{http_code}" http://localhost:8200/api/promptlab/fixtures`
       Expected: 401 (no JWT cookie)

    b. **Fixture list (check server doesn't crash):**
       Use the dev servers' list-servers script to verify servers are running.

    c. **Python smoke test:**
       ```python
       from core.promptlab import list_fixtures, load_fixture, regenerate_response
       fixtures = list_fixtures()
       assert len(fixtures) >= 2
       fixture = load_fixture(fixtures[0]["name"])
       assert fixture is not None
       assert len(fixture["messages"]) >= 4
       print("Backend smoke test passed")
       ```

    d. **Frontend build check:**
       `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run build` (should already pass but verify one more time with all files in place)

    e. **Lint check (full):**
       `cd /home/penguin/code/lens-platform/ws2 && ruff check core/promptlab/ web_api/routes/promptlab.py`
       `cd /home/penguin/code/lens-platform/ws2/web_frontend && npm run lint`

    Fix any issues found during these checks before proceeding to manual verification.
  </action>
  <verify>
    All automated checks pass: auth returns 401 for unauthenticated requests, Python smoke test passes, frontend builds, all linting passes.
  </verify>
  <done>
    Automated integration checks pass. Dev servers running. Ready for manual verification.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Manual end-to-end verification</name>
  <files></files>
  <action>
    Present the running Prompt Lab to the user for manual verification of the complete workflow. The user will test in their browser at http://dev.vps:3200/promptlab.

    What was built:
    - /promptlab page with auth gating (facilitator-only)
    - Fixture browser with module filtering
    - Two-panel layout: prompt editor (left) + conversation (right)
    - AI message selection and regeneration with SSE streaming
    - Original/regenerated comparison (collapsed by default)
    - Chain-of-thought display (collapsed by default)
    - Follow-up messaging as student
  </action>
  <verify>
    User verifies the following in their browser at http://dev.vps:3200/promptlab:

    1. Auth gate: unauthenticated users redirected to login, facilitator can access
    2. Fixture browser: 2 fixtures displayed with module filter working
    3. Two-panel layout: prompt editor (left) and conversation (right) side-by-side
    4. Prompt editing: edit text, see modified indicator, reset to original works
    5. Regeneration: click AI message to select, messages after it dim, click Regenerate, response streams progressively
    6. Comparison: original response appears collapsed above new response, expandable
    7. Chain-of-thought: "Show reasoning" toggle on regenerated messages
    8. Follow-up: type and send message as student, AI responds with streaming
  </verify>
  <done>
    User confirms "approved" -- the complete Prompt Lab workflow works end-to-end without critical issues.
  </done>
</task>

</tasks>

<verification>
1. /promptlab is accessible only to authenticated facilitators
2. Fixture browser loads and displays fixtures
3. Two-panel layout renders correctly
4. System prompt editing and reset works
5. AI message selection highlights correctly with dimming
6. Regeneration streams via SSE in real time
7. Original/regenerated comparison displays correctly
8. Chain-of-thought toggle works
9. Follow-up messaging works end-to-end
</verification>

<success_criteria>
- User confirms the complete Prompt Lab workflow works: load fixture -> edit prompt -> select message -> regenerate -> compare -> view reasoning -> continue conversation
- No critical bugs or layout issues
- SSE streaming is progressive (not buffered)
- Auth gate prevents non-facilitator access
</success_criteria>

<output>
After completion, create `.planning/phases/06-chat-evaluation/06-05-SUMMARY.md`
</output>
