---
title: "Credible Threats in Negotiations: Commitment and Endogenous Threats"
author: "Harold Houba, Wilko Bolt"
url: "https://link.springer.com/chapter/10.1007/0-306-47539-1_7"
---

# Chapter 7: Commitment and Endogenous Threats

## 7.1 Introduction

The bargaining problems with fixed disagreement actions studied in the previous chapters can be understood as representing the last 'phase' of some more complex negotiation model in which the parties choose the disagreement actions prior to the negotiations. This point of view requires that the 'fixed' disagreement actions will be carried out if the parties are called upon to do so.

This means that either players are committed upon these disagreement actions and cannot alter these actions if actually called upon to act, or the disagreement actions can be changed at will but these actions are anticipated as being credible, i.e., equilibrium actions, in case of a breakdown.

The ability to commit can be regarded as a powerful ingredient in negotiations. Intuitively, the underlying idea is that once a negotiator has convinced his opponents that he will not retreat from a specific course of action during the process, the opponents may decide to concede to his demands. Hence, deliberately reducing one's flexibility in the bargaining process may induce the other side to behave in a way that is favorable to the committed player. In this sense, we may say that in bargaining 'weakness may also represent a strength'. This was already understood by Thomas Schelling who was one of the first to informally explore the role, credibility and feasibility of commitment mechanisms in bargaining situations, e.g. Schelling (1960). In his view a bargaining process represents a struggle between negotiators to commit themselves to favorable bargaining positions. Obviously, the credibility of the mechanism which enforces these commitments is of great importance. A commitment which lacks credibility looses its strategic effect against rival opponents and they will merely regard this commitment action as a way of 'tactical bluffing' and act accordingly. Schelling further suggested that mutual incompatible commitments may cause bargaining impasses.

As lucidly described in Dixit and Nalebuff (1991), 'burning one's bridges' provides a good example of credible commitment. In the sixteenth century, in his conquest of Mexico, upon arrival in Cempoalla, Cortes commanded that all but one of his ships had to be destroyed, thus making an unconditional commitment to fight rather than to retreat. For his soldiers, although vastly outnumbered, there was no choice: to fight and win, or to loose and die. In fact, destroying the ships gave Cortes two advantages. First, his camp was unified, each soldier knowing that they would all fight till the end since desertion or even retreat was impossible. Second, and more important, was the effect this irreversible commitment to fight had on the enemy. The enemy knew that Cortes could only win or die, while they had the option to retreat into the hinterland. In the end, they chose to retreat rather than to fight such a determined opponent. The burning down of ships and Cortes' soldiers knowing it created a credible commitment to fight. If Cortes had failed it might well have seemed as an act of suicide. Yet, because he was victorious, it was the fruit of good strategic contemplation.$^1$ Still, these strategic commitment devices are at play in everyday bargaining situations. Consider for example a labour union engaged in collective wage bargaining which takes a firm position at the bargaining table by announcing a massive strike. It cannot back out from this announcement without 'losing its face'. If employers believe this to be true, then they may ultimately be better off by giving in to the union's demands.

In this chapter endogenous disagreement actions and the ability (not) to commit are studied in the simplest setting as is possible in order to understand the difference between the two notions. The natural starting point is Nash's variable-threat game, which is a simple two-stage model in which the parties commit themselves on their disagreement actions prior to the negotiations. This model can be easily modified to study negotiations without commitment, which we intend to do. Moreover, the negotiations in Nash's variable-threat game are modelled as Nash's demand game and, as extensively argued in section 4.3, the parties' demands can be regarded as representing the behavioural strategies of some underlying, unspecified dynamic bargaining process. The alternating offers procedure could represent this unspecified bargaining model given that it yields similar results. Therefore, it is obvious to replace Nash's demand game by the alternating offers model and study the issue of commitment versus no commitment in greater detail. Nevertheless, doing so does not yield duplicated results as will be seen below. Recall from chapter 6 that despite the rigid order of moves in the alternating offers model this procedure produces results that are robust if endogenous timing or some randomized sequence of proposing parties is taken into account.

This chapter is organized as follows. The starting point of the analysis is the introduction of Nash's variable threat game in the next section. After a brief analysis the unspecified negotiation process is explicitly modelled as the alternating offers procedure and the consequences are studied. Then, in the subsequent section, both models are studied under the assumption that players cannot commit themselves meaning that disagreement actions are chosen only in case of a breakdown. We note that the models without commitment can be regarded as simple in terms of mathematical complexity, because it is assumed that disagreement actions played in case of a terminal breakdown have no feedback on future behaviour in the negotiations (which are over by then).

## 7.2 Optimal Threats with Commitment

The simplest modification in terms of complexity is the extension in which the threats are chosen prior to the negotiations. As mentioned earlier, this requires that the players are committed to their disagreement actions if called upon to carry them out and players cannot back out from these actions. In the first subsection, Nash's variable-threat game is introduced and analyzed. Then, in the subsequent subsection, Nash's demand game that constitutes the second stage of the variable-threat game is replaced by the alternating offers procedure.

### 7.2.1 Nash's Original Variable-Threat Game

One of the first strategic bargaining games where players can influence the disagreement outcome was analyzed, not surprisingly, by Nash himself. In a now classical paper, e.g., Nash (1953), an elegant two-stage negotiation game is introduced, which is usually dubbed as Nash's variable-threat game. In the first stage, the players commit themselves to threats prior to the negotiations which they have to carry out in case they fail to reach an agreement in the second stage. In this second stage the players simultaneously play Nash's demand game of section 4.3.1. The multiplicity of equilibria in the latter model is resolved by resorting to the $H$-essential equilibrium of the demand game.

The latter means that the parties agree upon the axiomatic Nash bargaining solution and the choice of threats in the first stage actually determines the equilibrium agreement through the disagreement outcome in the second stage.

As a consequence, every player tries to choose its threat such as to increase its final payoff when agreement is struck.

For notational convenience, we briefly mention some of the notation already introduced in chapter 2. This means that the triple $\langle S, \{A_i\}_{i=1,2}, \{d_i\}_{i=1,2} \rangle$ specifies the non-empty and convex set $S$ of attainable utility pairs, player $i$'s set $A_i$ of 'threats' and player $i$'s utility function $d_i$ over the set of disagreement outcomes $A$. Assumption 2.7 implies that for each $a \in A$ there exists an agreement $s(a) \in S$ such that $d(a) \leq s(a)$, i.e. mutual interests. This means that the Pareto frontier in terms of utility pairs associated with disagreement outcomes in the set $A$ lies to the south-west of the Pareto frontier of the set $S$. Alternatively, we may regard the last two ingredients as representing a two-player game in normal form characterized by $\langle \{1, 2\}, \{A_i\}_{i=1,2}, \{d_i\}_{i=1,2} \rangle$, where $\{1, 2\}$ denotes the set of players, $A_i$ denotes player $i$'s set of 'threats' and $d_i$ denotes player $i$'s utility function.

Nash's variable-threat game is a two-stage game with almost perfect information, with two players and both players simultaneously and independently of each other choose their actions in each stage. In the first stage of the game, each player $i$, $i = 1, 2$, chooses his threat $a_i^* \in A_i$. Each player's threat determines this player's disagreement action in case the negotiations of the second stage break down and it is assumed that each player is committed to his threat in case of such breakdown. Once the threats have been chosen by the players, each player observes the threat chosen by his opponent. Then the game moves to the second stage which consists of Nash's demand game, as already described in section 4.3.1. Briefly recalling, the players simultaneously and independently state their demands $x_i \in \mathbb{R}$ in terms of utility and if the players' demands are compatible, i.e. $x \in S$, then both demands can be fulfilled, each player obtaining $x_i$, $i = 1, 2$, and the game ends. If both demands are incompatible, i.e. $x \notin S$, then players fail to reach agreement and have to carry out their threats $a^*$, each player securing $d_i(a^*)$, $i = 1, 2$, and the game ends. The formal definition of Nash's variable-threat game is as follows.

**Bargaining Procedure 7.1.** *Nash's variable-threat game is the two-stage game with almost perfect information characterized by the set of players $N = \{1, 2\}$, player $i$'s threat $a_i^* \in A_i$ in the first stage, player $i$'s demand $x_i \in \mathbb{R}$ in the second stage, and player $i$'s utility function $d_i(a^*) + \iota(x)(x_i - d_i(a^*))$, where the indicator function $\iota(x)$ is defined in bargaining procedure 4.29.*

As argued in chapter 2 the equilibrium concept for multi-stage games with almost-perfect information is the SPE concept. Unfortunately, this concept is rather weak in Nash's variable-threat game, because it only imposes that a Nash equilibrium of the demand game is played in the second stage. As already discussed in section 4.3.1, under quite general conditions the Nash demand game admits a continuum of equilibria: any possible agreement which is both Pareto efficient and individually rational corresponds to a particular Nash equilibrium. In the variable-threat game this multiplicity problem aggravates, because the SPE strategies allow for the Nash equilibrium to depend upon the threats chosen in the first stage. Formally, every vector function $x^*: A \to \mathbb{R}^2$ describes the players' SPE strategies in the second stage of the threat game if and only if $x^*(a^*)$, $a^* \in A$, is a Nash equilibrium of Nash's demand game. In order to deal with this indeterminacy, John Nash proposed the equilibrium selection described in section 4.3.1. In modern terminology, the $H$-essential equilibrium concept is applied to the second stage and according to theorem 4.31 the unique $H$-essential equilibrium of the second stage is given by $x^*(a^*) = N(S, d(a^*))$ for $d = d(a^*)$. So, the players' demands coincide with the axiomatic Nash bargaining solution of chapter 4. Recall that this solution is Pareto efficient, which is important in the sequel.

Having 'solved' the SPE strategies for the second stage means that the analysis continues with deriving the optimal threats in the first stage of the variable-threat game. Imposing the $H$-essential equilibrium outcome of the demand game as the SPE continuation in the variable-threat game means that both players anticipate agreement upon $x^*(a^*) = N(S, d(a^*))$ in the second stage. Then the SPE actions in the first stage of the threat game correspond to the Nash equilibrium actions of the game in normal form in which $A_i$, $i = 1, 2$, represents player $i$'s set of feasible actions and $N_i(S, d(a^*))$ represents player $i$'s utility. In Nash (1953) it is argued that the latter game is strategically equivalent to a zero-sum game, because Pareto efficiency of the agreement implies that an improvement enforced by one player is at the expense of his opponent.

This equivalence has several important implications. First, zero-sum games are known to have a unique value meaning that there exists a unique number that expresses player 1's Nash equilibrium utility and, due to the antagonistic character of zero-sum games, it also expresses player 2's utility. Translated to the threat game, this means that there is uniqueness in terms of a unique utility pair on the Pareto frontier. So, the threat game resolves in a unique Pareto efficient agreement. With respect to the equilibrium threats, (generic) uniqueness cannot be established, because zero-sum games like all other games often admit multiple Nash equilibria for a generic class of problems.$^2$ Second, all Nash equilibrium actions in zero-sum games are minmax strategies and vice versa. A minmax strategy for player 1 maximizes this player's worst outcome his opponent can impose upon him and, due to the antagonistic setting, player 2 has every incentive to keep player 1 down at his lowest utility level. Translated to the threat game this means that $(a_1^*, a_2^*)$ are SPE disagreement actions in the first stage if and only if

$$a_i^* = \arg \max_{a_i^* \in A_i} \min_{a_j^* \in A_j} N_i\left(S, d(a^*)\right), \quad i, j = 1, 2, \quad j \neq i. \tag{7.1}$$

So, player 1 wants to pull the bargaining solution along the Pareto frontier in the south-east direction, whereas his opponent wants to pull it in the opposite direction. Finally, minmax strategies are said to be interchangeable meaning that if $a_i^*$ and $a_i^{**}$ are both minmax strategies for player $i$, then both actions do equally well against all of his opponents minmax actions and player $i$ can choose any of these two actions regardless of what his opponent will choose.

This implies that the players in a zero-sum game that admits multiple Nash equilibria do not have the coordination problem of playing the same Nash equilibrium actions as other games in normal form have, as for example the battle of the sexes.

We state the following proposition without further proof.

**Theorem 7.2.** *Consider the class of SPE strategies in which the players play the $H$-essential equilibrium $x^*(a^*) = N(S, d(a^*))$ in the second stage.*

*i. Then $a^* \in A$ is a pair of SPE threats in the first stage of Nash's variable-threat game if and only if for both $i = 1, 2$ the threat $a_i^*$ is a minmax action associated with (7.1).*

*ii. All SPE strategies result in the same Pareto efficient agreement in $S$, i.e., there exist a unique $s^* \in S$ such that $x^*(a^*) = s^*$ for all SPE threats $a^*$.*

This proposition is illustrated in the following example.

**Example 7.3.** *Consider the class of variable-threat games such that the set $S$ is given by*

$$S = \left\{ s \in \mathbb{R}^2_+ \mid s_1 + s_2 \leq 1 \right\}.$$

*The $H$-essential equilibrium concept singles out the equilibrium demands $x^*(a^*) = N\left(S, d(a^*)\right)$ in the second stage that are given by*

$$x^*(a^*) = \tfrac{1}{2}\left(1 + d_1(a^*) - d_2(a^*), 1 - d_1(a^*) + d_2(a^*)\right), \quad a^* \in A.$$

*According to theorem 7.2, in choosing optimal threats, player 1 tries to maximize the quantity $d_1(a^*) - d_2(a^*)$, whereas player 2 tries to minimize this same quantity. Effectively, this means that the players play a zero-sum game in which $d_1(a^*) - d_2(a^*)$ represents player 1's utility function. The optimal threats $a^*$ need to constitute a Nash equilibrium of this zero-sum game.*

### 7.2.2 The Variable-Threat Game with Alternating Offers

As argued in section 4.3.2, John Nash thought of the demands as representing the players' strategies of some unspecified bargaining procedure. In this section we replace the demand game by one specific bargaining procedure, being the procedure with alternating offers. Since this procedure showed quite some robustness with respect to alternative bargaining procedures, as shown in chapter 6, there is not much loss in generality by choosing this specific bargaining procedure. At first glance the reader might consider this exercise as being trivial, because the unique SPE of the alternating offers also corresponds to the Nash bargaining solution. However, we will show that the results of theorem 7.2 need to be modified unless some additional assumption is imposed.

Like in the previous section we consider bargaining problems in utility representation $\langle S, \{A_i\}_{i=1,2}, \{d_i\}_{i=1,2} \rangle$. The choice of the threats takes place prior to the negotiations and, similar as before, we adopt the convention that the first bargaining round takes place at $t = 0$ meaning that the choice of disagreement actions takes place at let's say $t = -1$. It is again assumed that each player perfectly observes the other player's choice of disagreement actions before the negotiations start at round $t = 0$ and this guarantees that the players have perfect information in the bargaining process. For explanatory reasons we think of $\delta \in (0, 1)$ as representing the probability of a next bargaining round. By doing so, a breakdown is an irreversible event once it occurs. A novel feature is that we assume that the players may condition their disagreement actions upon the bargaining round in which breakdown occurs. Therefore, the players choose an infinite sequence of actions $(a_i^t)_{t=0}^{\infty}$, $a_i^t \in A_i$, before the negotiations start.

Let us therefore state the informally described bargaining procedure.

**Bargaining Procedure 7.4.**

*Round $-1$:*
*Player $i$, $i = 1, 2$, chooses the infinite sequence of disagreement actions $(a_i^t)_{t=0}^{\infty}$, $a_i^t \in A_i$.*

*Round $t$ ($t$ even, $t \geq 0$):*
*Player 1 proposes an offer $s^t \in S$ and, then, player 2 either accepts ('yes') or rejects ('no') the offer $s^t$. If player 2 accepts, then the negotiations end and the players implement the offer $s^t$ yielding a final utility $s_i^t$, $i = 1, 2$, in round $t$. However, if player 2 rejects, then with probability $\delta \in [0, 1)$ the bargaining process continues to the next round $t + 1$, and with probability $1 - \delta$ the bargaining process breaks down forever and the players are committed to carry out the pair of disagreement actions chosen at round $-1$ with associated pair of utilities $d(a^t)$, $a^t \in A$.*

*Round $t$ ($t$ odd, $t \geq 1$):*
*The procedure is similar as for $t$ is even except that now player 2 has the initiative to propose an offer $s^t \in S$ and, afterwards, player 1 responds.*

As in Nash's variable-threat game the bargaining procedure is a multi-stage game with almost-perfect information and the SPE concept is appropriate. This implies that the alternating offers has to be solved for every possibly infinite sequence of actions $(a_i^t)_{t=0}^{\infty}$. Since these actions change over time, the disagreement point will also vary over time, which include the special case of alternating disagreement points studied in section 6.3.2. Recall that alternating disagreement points cause the technical problem that the standard analysis is only applicable if some 'constructed' disagreement point is taken into account. The latter point may lie above the Pareto frontier of the set $S$ and generic multiplicity cannot be ruled out. In this section we want to avoid these technical problems by restricting the analysis to the class of normalized bargaining problems with a linear Pareto frontier, that is, we assume,

$$S = \left\{ s \in \mathbb{R}^2 \mid s_1 + s_2 \leq 1 \right\}. \tag{7.2}$$

This implicitly means that we also impose $d_1(a) + d_2(a) \leq 1$ for all $a \in A$. Consider an arbitrary subgame starting at the first bargaining round after the players have chosen their disagreement actions. This means that the infinite sequence of actions $(a^t)_{t=0}^{\infty}$, $a^t \in A$, is given and observed by the two players.

The corresponding subgame is equivalent to a non-stationary version of the alternating offers procedure, because the disagreement actions may vary over time. The first lemma states the unique SPE payoff of the subgame starting at the first bargaining round. A proof can be found in Busch and Wen (1995) and is therefore omitted.

**Lemma 7.5.** *For every infinite sequence of disagreement actions $(a^t)_{t=0}^{\infty}$ the alternating offers process admits a unique SPE. Moreover, at $t = 0$ the players immediately agree upon the SPE proposal $x(\delta, (a^t)) \in S$ given by*

$$x_1(\delta, (a^t)) = (1 + \delta)^{-1} + (1 - \delta) \sum_{k=0}^{\infty} \delta^{2k} \left[ -d_2(a^{2k}) + \delta d_1(a^{2k+1}) \right]$$

*and*

$$x_2(\delta, (a^t)) = 1 - x_1(\delta, (a^t)).$$

Having solved for the SPE utilities at $t = 0$ means that the choice of the equilibrium disagreement actions at $t = -1$ simply boils down to playing a normal-form game in which player $i$, $i = 1, 2$, chooses an infinite sequence of actions $(a_i^t)_{t=0}^{\infty}$ with payoff function $x_1(\delta, (a^t))$. Moreover, this normal-form game is equivalent to a zero-sum game, which is similar as in Nash's variable-threat game.

This zero-sum game is easy to solve. First, the utility function $x_1(\delta, (a^t))$ is linear in the disagreement payoffs $d_2(a^{2k})$ and $d_1(a^{2k+1})$, $k \in \mathbb{N}$, and independent of the disagreement payoffs $d_1(a^{2k})$ and $d_2(a^{2k+1})$. Therefore, we can divide the 'large' zero-sum game into infinitely many smaller subproblems, each of them also being a zero-sum game. So, $a^{2k}$, $k \in \mathbb{N}$, is found by solving the smaller zero-sum game with player 1's utility function equal to $-d_2(a^{2k})$. The unique value of this smaller zero-sum game is simply the minmax value, as explained in section 7.2.1. Now, von Neumann's famous minmax theorem for two-player zero-sum games states that the minmax value is equal to the maxmin value, e.g., von Neumann (1928) or Mas-Colell, Whinston, and Green (1995).

Hence, player 2's value for this zero-sum game is equal to his minmax value $m_2$ as already defined in chapter 2. Formally, the pair of SPE disagreement actions $a^{2k}$, $k \in \mathbb{N}$, is given by

$$a_1^{2k} = \arg \max_{a_1 \in A_1} \left[ \min_{a_2 \in A_2} -d_2(a) \right] \quad \text{and} \quad a_2^{2k} = \arg \max_{a_2 \in A_2} \left[ \min_{a_1 \in A_1} d_2(a) \right], \tag{7.3}$$

where the argument, i.e., arg, only refers to the maximization. For a good understanding: The action $a_1^{2k}$ corresponds to player 1's minmax strategy that keeps player 2 at the utility level $m_2$. Recall from chapter 2 that the set of actions that minmax player 2 is denoted as $A^2$. Similar, the SPE disagreement actions $a^{2k+1}$, $k \in \mathbb{N}$, solve the smaller zero-sum game in which player 1's utility function is equal to $d_1(a^{2k+1})$ and the corresponding minmax actions are

$$a_1^{2k+1} = \arg \max_{a_1 \in A_1} \left[ \min_{a_2 \in A_2} d_1(a) \right] \quad \text{and} \quad a_2^{2k+1} = \arg \max_{a_2 \in A_2} \left[ \min_{a_1 \in A_1} -d_1(a) \right]. \tag{7.4}$$

This implies that the (mixed) actions in $A^i$, $i = 1, 2$, are the Nash equilibrium actions in a two-player zero-sum game with payoff functions $d_i(a)$, $a \in A$, for player $i$ and $-d_i(a)$ for the other player. As in chapter 2, the set of actions that minmax player 1 is denoted as $A^1$. A final substitution of $d_2(a^{2k}) = m_2$ and $d_1(a^{2k+1}) = m_1$ into the expressions of lemma 7.5 yields the elegant expression

$$x(\delta, (a^t)) = \tfrac{1}{1+\delta}(1 + \delta m_1 - m_2, \delta + m_2 - \delta m_1).$$

These arguments imply the following proposition.

**Proposition 7.6.** *The sequence $(a^t)_{t=0}^{\infty}$, $a^t \in A$, is a sequence of SPE threats at $t = -1$ if and only if*

$$a^t \in \begin{cases} A^2, & \text{if } t \text{ is even,} \\ A^1, & \text{if } t \text{ is odd.} \end{cases}$$

*Moreover, $x(\delta, (a^t)) = \tfrac{1}{1+\delta}(1 + \delta m_1 - m_2, \delta + m_2 - \delta m_1)$ is the unique SPE agreement for all SPE sequences $(a^t)_{t=0}^{\infty}$ and $x(\delta, (a^t))$ converges to the axiomatic Nash bargaining solution $N(S, (m_1, m_2))$ as $\delta$ goes to 1.*

From proposition 7.6 it is clear that the equilibrium disagreement actions alternate over time. Moreover, the disagreement actions are independent of the probability $\delta$. This result is quite different from the result obtained in theorem 7.2 or, given the linear Pareto frontier, example 7.3, where the disagreement actions are equilibrium actions of the zero-sum game with player 1's utility given by $d_1(a) - d_2(a)$. A similar result can only be obtained in the modified model of this section by imposing the restriction $a^t = a$ for all $t \in \mathbb{N}$ to the sequence $(a^t)_{t=0}^{\infty}$. Doing so, would mean that

$$x(\delta, (a^t)) = \tfrac{1}{1+\delta}(1 + \delta d_1(a) - d_2(a), \delta + d_2(a) - \delta d_1(a))$$

and the SPE threats $a \in A$ solve a zero-sum game in which player 1's utility is given by $\delta d_1(a) - d_2(a)$. Thus, the associated equilibrium threats now depend upon the probability $\delta$. Then, as $\delta$ goes to 1, the player 1's utility function converges to this player's utility function as derived in example 7.3. Without going into the details, it can be shown that the set of Nash equilibria is upper semi-continuous in $\delta \in [0, 1]$ and this suffices for the set of SPE disagreement actions corresponding to $\delta d_1(a) - d_2(a)$ to converge to some subset of the set of optimal threats of example 7.3. Thus, we have arrived at the following theorem.

**Theorem 7.7.** *Let the set of sequences $(a^t)_{t=0}^{\infty}$ be restricted to sequences such that $a^t = a$, $a \in A$, $t \in \mathbb{N}$. Then, as $\delta$ goes to 1, the limit set of SPE disagreement actions of bargaining procedure 7.4 is contained in the set of SPE disagreement utilities in Nash's variable threat game.*

Note that the limit set of Nash equilibrium of theorem 7.7 is always contained in the set of equilibrium actions corresponding to Nash's variable-threat game and that it could be a strict subset in which case this limit set can be regarded as a refinement.$^3$ In the previous section the $H$-essential equilibrium was proposed on an ad hoc basis, whereas the analysis in this section can be regarded as a more plausible underpinning. First, the demand game represents the reduced normal-form of the alternating offers model and, second, players are not allowed to condition their disagreement actions upon the exact bargaining round in case of a breakdown occurs. So, we may say that in Nash (1953) it is implicitly assumed that the disagreement actions $a^t$, $a^t \in A$, are constant, i.e. $a^t = a$ for all $t \in \mathbb{N}$, during the underlying unspecified dynamic bargaining process. If the players are able to condition the disagreement actions upon the exact round of breakdown, then the actions drift away from the equilibrium threats in Nash's variable-threat game.

## 7.3 Credible Threats Without Commitment

The assumption of commitment is restrictive in that it requires an adequate enforcement mechanism for the players to stick to their threats in case of breakdown. Without commitment each player is free to choose his disagreement actions in case of a breakdown and each player will only carry out a previously announced threat if it is still in the best interest of this party to do so. The SPE threats derived in the previous section often induce a player to choose a threat which may indeed hurt himself if he is forced to carry it out. Thus, we can not expect that the SPE threats under commitment survive in any environment where an adequate enforcement is proven infeasible and this calls for a new analysis, which is conducted in this section.

In the first section we remove the enforcement of commitment in Nash's variable-threat game. This means that the players cannot commit themselves upon the disagreement actions before the negotiations start. Instead, the players choose their disagreement actions only in case of a breakdown. In this section also briefly touch upon the question whether or not the parties would choose to commit if adequate enforcement would be at their disposal. Then we proceed by replacing the unspecified negotiation process thought to underlie Nash's demand game by the alternating offers process. The latter model also serves as a first step to the more complex bargaining models that are postponed to subsequent chapters. The analysis is conducted in several subsections. In the first equilibria in Markov strategies are investigated. Then the set of SPE utility pairs is characterized and necessary and sufficient conditions for uniqueness are derived. Finally, the limit set of SPE utility pairs is investigated as the risk of breakdown vanishes.

One remark is in place. Here, the disagreement actions are chosen in case of a breakdown and, therefore, the players' past behaviour in the negotiations can influence the disagreement actions but not vice versa. The absence of this feedback will be restored in latter chapters.

### 7.3.1 Nash's Variable-Threat Game: No Commitment

In case the enforcement of commitment is removed from Nash's variable-threat game the players choose their disagreement actions only in case of a breakdown. So, disagreement actions are no longer chosen prior to the negotiations but after the negotiations ended, i.e., a permanent breakdown occurred, meaning the demand game is played first and only in case of incompatible demands the disagreement actions are chosen.

From here on we consider the triple $\langle S, \{A_i\}_{i=1,2}, \{d_i\}_{i=1,2} \rangle$ without additional assumptions other than the by now standard assumptions made in chapter 2. Recall that the assumption of mutual interests means that the Pareto frontier in terms of utility pairs associated with disagreement outcomes in the set $A$ lies to the south-west of the Pareto frontier of the set $S$. The last two terms of the triple specify the disagreement game in case of a breakdown. The assumptions made in chapter 2 ensure that the set of Nash equilibria of this disagreement game, denoted as $A^N \subseteq A$, is a non-empty and compact set.

The formal definition of Nash's variable-threat game without commitment runs now as follows.

**Bargaining Procedure 7.8.** *Nash's variable-threat game without commitment is the two-stage game with almost perfect information characterized by the set of players $N = \{1, 2\}$ and player $i$'s demand $x_i \in \mathbb{R}$, $i = 1, 2$, in the first stage. In case $x \in S$, i.e., compatible demands, the negotiations end with the agreement $x$. Otherwise, the game proceeds to the second stage where player $i$ chooses his threat $a_i^* \in A_i$. Player $i$'s utility function $d_i(a^*) + \iota(x)(x_i - d_i(a^*))$, where the indicator function $\iota(x)$ is defined in bargaining procedure 4.29.*

As before, the two-stage game has almost perfect information and the SPE concept is the appropriate solution concept. Note that strategies specify actions at the second stage conditional upon the history $x \notin S$ meaning that strategies prescribe some function $a_i^*: \mathbb{R}^2 \to A_i$, $i = 1, 2$, that specifies player $i$'s action at the second stage. Now, application of the SPE concept implies that the actions played at the final stage of the game are Nash equilibrium actions.

Thus, every SPE strategy satisfies $a^*(x) \in A^N$ for all $x \notin S$. The simplest functions specify the same Nash equilibrium for every subgame, i.e. there exists a $a^N \in A^N$ such that $a^*(x) = a^N$ for all $x \notin S$. The latter is the only possibility in case the disagreement game admits a single Nash equilibrium.

However, with multiple Nash equilibria in the disagreement game numerous discontinuous functions can also be constructed, but we will not pursue this line of research. So, for explanatory simplicity we assume SPE functions of the first form only.

At the first stage, the players have to state their demands while both anticipate the same Nash equilibrium $a^N \in A^N$ to be played in case of incompatible demands. It will be clear that for every $a^N \in A^N$ the multiplicity of equilibrium demands as discussed in section 4.3.1 arises. Thus, the SPE concept has too little bite in the two-stage game and, again, we resort to the $H$-essential equilibrium of the demand game to obtain some results. Doing so means that we simply characterize SPE strategies as follows: For some $a^N \in A^N$ the SPE demands in the first stage are $x^* = N(S, d(a^N))$ and the disagreement actions $a^*(x) = a^N$ for all $x \notin S$. These strategies induce agreement upon the compatible demands $x^* = N(S, d(a^N))$ at the first stage and permanent breakdown never occurs, i.e., the second stage is never reached along any SPE path.

**Proposition 7.9.** Consider the class of SPE strategies in which for some $a \in A$ the threats $a^*(x) = a$, $x \notin S$, and the players play the $H$-essential equilibrium $x = N(S, d(a))$ at the first stage. Then these strategies are SPE strategies if and only if $a \in A^N$. Moreover, the set of SPE outcomes consists of the set of compatible demands (or agreements)

$$\left\{ x \in S \mid x = N(S, d(a^N)), \; a^N \in A^N \right\}. \tag{7.5}$$

From this results it follows that the ability (not) to commit has a huge impact on the type of results that can be obtained. First, at the heart of Nash's variable-threat game lies the assumption of irrevocable commitment to the ex-ante specified threats $a^* \in A$. However, note that in general the SPE disagreement actions of theorem 7.2 do not constitute a Nash equilibrium of the disagreement game, i.e. $a^* \notin A^N$, as is clearly demonstrated by example 7.24.

This simple observation alone requires the existence of some strong commitment device, because, by definition, in a non-cooperative environment players cannot be assumed to play one-shot non-credible actions. As Nash (1953), (p. 130), puts it:

... we must assume there is an adequate mechanism for forcing the players to stick to heir threats and demands once made; and one to enforce the bargain, once agreed. Thus, we need a sort of umpire, who will enforce contracts or commitments.

**Proposition 7.9** states a one-to-one relationship between the Nash equilibrium actions in $A^N$ and the set of SPE outcomes, provided the class of SPE strategies is restricted. Note that we no longer can guarantee uniqueness of the SPE agreement as in Nash's variable-threat game unless all Nash equilibria of the disagreement game result in the same agreement, i.e., there exists a $s^* \in S$ such that $x^*(a^N) = s^*$ for all $a^N \in A^N$. The latter condition can be reinterpreted in terms of the second geometrical property of the axiomatic Nash bargaining solution, as discussed in section 4.2.2. Consider one particular $a^N \in A^N$ and suppose the function $f_1$ (or $f_2$) that describes the Pareto frontier of $S$, i.e., $(f_1(s_2), s_2)$ lies on the Pareto frontier, is differentiable. Then uniqueness requires that for all $a^N \in A^N$ the line through $d(a^N)$ and $N(S, d(a^N))$ coincides with the line through $d(a^{N'})$ and $N(S, d(a^{N'}))$ for $a^{N'} \in A^N$. So, in order to have a unique SPE agreement all disagreement points corresponding to Nash equilibria of the disagreement game should lie on one line and all the associated SPE demands should also lie on this line. This condition trivially holds for the class of disagreement games that admit a single Nash equilibrium. However, outside this class this condition is nongeneric. This implies the following proposition.$^4$

**Proposition 7.10.** Let $f_1$ be differentiable. Then Nash's variable-threat game without commitment admits a unique SPE agreement if $A^N$ consists of a single element and it generically admits multiple SPE agreements otherwise.

This result implies that the uniqueness of the SPE agreement obtained for the case with commitment is only partially preserved. Since disagreement points are linked in both models to the compatible SPE demands in the same manner and SPE threats differ, this implies that the SPE agreements are different as well.

To conclude, suppose the possibility of some costless but strong commitment device is available to each of the players and that each player has a choice whether or not to commit upon his threat prior to the negotiations, where a player who does not wish to commit remains flexible in choosing his disagreement point in case of a breakdown. What should each player do? Commit or remain flexible? In Mao (1993) this important question is addressed. The answer is that each player chooses to commit himself prior to the negotiations.

The underlying intuition is rather simple. Suppose that both players do not commit. Then a deviation by let us say player 1 to commit himself prior to the negotiations means that this player sets his threat before his opponent does and that his opponent has to react to player 1's choice, which cannot be undone due to the commitment. Then player 1 can be regarded as the leader in the famous Stackelberg equilibrium from industrial organization, e.g., Fudenberg and Tirole (1991), Mas-Colell, Whinston, and Green (1995) and Tirole (1988), and it is known that the leader can always obtain the Nash equilibrium profit of the symmetric Cournot or Bertrand model, whichever is considered.

Manoeuvering oneself in the position of the 'leader' is not only profitable in the Stackelberg model, but also in the negotiations with endogenous threats for the same underlying reason. So, both players refraining from committing themselves cannot be an SPE outcome. In Mao (1993) it is further shown that the outcome in which one player refrains from committing himself cannot be an SPE outcome either, because this player can do better by choosing to commit himself upon a suitable threat. Hence, if costless commitment devices are available, both players will commit themselves.

### 7.3.2 Variable Threats with Alternating Offers: No Commitment

For similar reasons as in section 7.2.2 we replace the demand game by the alternating offers procedure and investigate SPE utility pairs. In this section the bargaining procedure is specified and SPE in Markov strategies are derived. In the subsequent sections we derive upper and lower bounds upon the players' SPE utilities and characterize the set of SPE utility pairs.

Consider the class of triples $\langle S, \{A_i\}_{i=1,2}, \{d_i\}_{i=1,2} \rangle$ that satisfy the assumptions made in chapter 2. Bargaining procedure 7.8 is modified to allow for alternating offers and becomes the following bargaining procedure.

**Bargaining Procedure 7.11.**

*Round $t$ ($t$ even, $t \geq 0$):*
Player 1 proposes an offer $s^t \in S$ and, then, player 2 either accepts ('yes') or rejects ('no') the offer $s^t$. If player 2 accepts, then the negotiations end and the players implement the offer $s^t$ yielding a final utility $s_i^t$, $i = 1, 2$, in round $t$. However, if player 2 rejects, then with probability $\delta \in [0, 1)$ the bargaining process continues to the next round $t + 1$, and with probability $1 - \delta$ the bargaining process breaks down forever and players play the disagreement game once that determines the final disagreement outcome $d(a^t)$, $a^t \in A$.

*Round $t$ ($t$ odd, $t \geq 1$):*
The procedure is similar except that now player 2 has the initiative to propose an offer $s^t \in S$ and, afterwards, player 1 responds.

As before, this bargaining procedure is a multi-stage game with almost perfect information and we therefore apply the SPE concept. As in section 7.3.1 the strategies specify disagreement actions in round $t$, $t \in \mathbb{N}$, in case of a breakdown at this round conditional upon the history $h_2(t)$ meaning that strategies prescribe some function $a_i^t : H_2(t) \to A_i$, $i = 1, 2$, that specify player $i$'s action at the second stage. Now, application of the SPE concept implies that the actions played at the final stage of the game are Nash equilibrium actions. Thus, every SPE strategy satisfies $a^t(h_2(t)) \in A^N$ for all $h_2(t) \in H_2(t)$ including a permanent breakdown in round $t$. The following lemma summarizes the main results in this (sub)section.

**Lemma 7.12.** Consider a pair of strategies $\sigma$ such that $a^t(h_2(t))$ are the disagreement actions at round $t$, $t \in \mathbb{N}$, for histories $h_2(t) \in H_2(t)$ that include a breakdown in round $t$. If the strategies $\sigma$ are SPE strategies, then $a^t(h_2(t)) \in A^N$ for all $h_2(t) \in H_2(t)$ and all $t$. Recall from section 2.3.8 that Markov strategies are, loosely stated, restricted to the 'payoff-relevant' history of the play. For the bargaining model under consideration, Markov strategies ignore all past offers that have been rejected and do not condition the disagreement actions on the bargaining round in which breakdown occurs. Formally, this means that Markov strategies impose (among others) that there exists an $\bar{a} \in A$ such that $a^t(h_2(t)) = \bar{a}$ for all rounds $t$, $t \in \mathbb{N}$, and histories $h_2(t) \in H_2(t)$ that include a breakdown in round $t$. Thus, Markov strategies induce the simplest function possible upon the disagreement actions $a^t : H_2(t) \to A$. Combined with lemma 7.12 this immediately implies that in every MPE strategy $a^t(h_2(t)) = a^N$ for some $a^N \in A^N$. The full derivation of MPE strategies then becomes almost trivial. Since the disagreement actions do not depend upon time nor on the history of proposals during the negotiations we can replace the infinite sequence of endogenous disagreement points by a time-independent disagreement point and analyze the alternating offers with this disagreement point. Doing so means that we analyze the standard alternating offers of chapter 3, where $d$ is equal to $d(a^N)$ for some $a^N \in A^N$. The results obtained in the latter chapter immediately apply leading to the following proposition.

**Proposition 7.13.** For $a^N \in A^N$ let $x^*(\delta, d(a^N))$ and $y^*(\delta, d(a^N))$ form the unique fixed point of the function $\mathbf{p} \times \mathbf{q}$ for $d = d(a^N)$, where $\mathbf{p} \times \mathbf{q}$ is defined in (3.1) of section 3.3.1. Then the Markov strategies of table 7.1 are SPE strategies in bargaining procedure 7.11. Moreover, in the limit, as $\delta$ goes to 1, both $x^*(\delta, d(a^N))$ and $y^*(\delta, d(a^N))$ converge to the axiomatic Nash bargaining solution $N(S, d(a^N))$.

Note that each Nash equilibrium in $A^N$ corresponds to one particular pair of MPE strategies in the bargaining model. Since the set $A^N$ is non-empty it immediately follows that the set of Markov perfect equilibria is non-empty as well. Hence, this implies existence of at least one such equilibrium.

### 7.3.3 Bounds for SPE Utilities

Upper and lower bounds upon SPE utilities are derived by modifying the method of Shaked and Sutton, as extensively discussed in section 3.4.1. Lower and upper bounds upon SPE utilities require knowledge of these bounds in the 'final' subgame associated with permanent breakdown. Since SPE disagreement actions correspond to some pair of actions in $A^N$ contingent upon the exact history of the negotiations each player's lowest and highest utilities in the final subgame coincide with this player's extreme Nash equilibria in $A^N$. Formally, for each player $i$, $i = 1, 2$, the minimum and maximum Nash equilibrium utilities in $A^N$ are defined as

$$n_i = \min\{d_i(a^N) \mid a^N \in A^N\} \quad \text{and} \quad N_i = \max\{d_i(a^N) \mid a^N \in A^N\}$$

(the symbol $N_i$ is used twice, namely for $N_i$ and $N_i(S, d)$, and it will be clear from the context which interpretation $N_i$ should have) and the corresponding Nash equilibrium actions which attain these payoffs are defined by

$$\underline{a}^i = \arg\min_{a^N \in A^N} d_i(a^N) \quad \text{and} \quad \bar{a}^i = \arg\max_{a^N \in A^N} d_i(a^N).$$

By definition $d_2(\bar{a}^2) = N_2$ and $n_1 \leq d_1(\bar{a}^2)$ and $d(\bar{a}^2) \in S^{IR}$ imply that $(n_1, N_2) \leq d(\bar{a}^2)$ and $d(\bar{a}^2) \in S^{IR}$. Similar arguments apply to $(N_1, n_2) \in S^{IR}$. We arrived at the following crucial result in the analysis.

**Lemma 7.14.** The utility pairs $(n_1, N_2)$ and $(N_1, n_2)$ belong to $S^{IR}$.

Before deriving the lower and upper bounds on the players' SPE payoffs, we postulate a pair of strategies with alternating disagreement actions and show that these strategies are SPE strategies. The rationale is simple. Consider a linear Pareto frontier and player 1's utility of lemma 7.5 once more, i.e.,

$$(1+\delta)^{-1} + (1-\delta) \sum_{k=0}^{\infty} \delta^{2k} \left[ -d_2(a^{2k}) + \delta d_1(a^{2k+1}) \right].$$

Observe that player 1's utility depends positively on his disagreement payoff $d_1(a^{2k+1})$ if breakdown occurs in a round in which player 1 responds, and negatively on player 2's disagreement payoff $d_2(a^{2k})$ if breakdown occurs in a round in which player 2 is the responding player. Therefore, in order to incur the greatest loss of delay on player 1's utility given that SPE disagreement actions always belong to player 1's disagreement utility $d_1(a^{2k+1})$, $k \in \mathbb{N}$, are minimized if the actions $\underline{a}^1$ are played in case of a breakdown in every even period. The opposite case applies to player 2's disagreement utilities $d_2(a^{2k})$, $k \in \mathbb{N}$, that are maximized by the actions $\bar{a}^2$ in case of a breakdown in every odd period. The latter actions minimize the loss of delay on player 2's payoff and, thereby, strengthen his bargaining position. So, player 1's utility becomes $(1+\delta)^{-1}(1+\delta n_1 - N_2)$. This idea also works in general, especially because lemma 7.14 ensures that the constructed disagreement point $d = (n_1, N_2)$ lies below the Pareto frontier of $S^{IR}$. This rules out the multiplicity encountered in section 6.3.2. The informally described strategies are formally presented by table 7.2 for general bargaining problems, where $x^*(\delta, d)$ and $y^*(\delta, d)$ refer to the unique fixed point of the function $\mathbf{p} \times \mathbf{q}$ for $d = (n_1, N_2)$. The next proposition states that the strategies of table 7.2 are SPE. As will be shown in theorem 7.17 below these SPE strategies constitute player 1's worst pair of SPE strategies.

**Proposition 7.15.** Let $x^*(\delta, (n_1, N_2))$ and $y^*(\delta, (n_1, N_2))$ form the unique fixed point of the function $\mathbf{p} \times \mathbf{q}$ for $d = (n_1, N_2)$, where $\mathbf{p} \times \mathbf{q}$ is defined in (3.1). Then the strategies of table 7.2 are SPE strategies for all $\delta \in [0, 1)$. Moreover,

$$\lim_{\delta \to 1} x^*(\delta, (n_1, N_2)) = \lim_{\delta \to 1} y^*(\delta, (n_1, N_2)) = N(S, (n_1, N_2)).$$

By reversing the roles of both players in the previous proposition we obtain player 2's worst pair of SPE strategies.

**Proposition 7.16.** Let $x^*(\delta, (N_1, n_2))$ and $y^*(\delta, (N_1, n_2))$ form the unique fixed point of the function $\mathbf{p} \times \mathbf{q}$ for $d = (N_1, n_2)$. Then the strategies that are obtained by reversing the roles of the players in table 7.2 are SPE strategies for all $\delta \in [0, 1)$. Moreover,

$$\lim_{\delta \to 1} x^*(\delta, (N_1, n_2)) = \lim_{\delta \to 1} y^*(\delta, (N_1, n_2)) = N(S, (N_1, n_2)).$$

Note that the strategies of table 7.2 are non-Markov, since the disagreement actions played in case of breakdown do depend on the specific bargaining round in which breakdown occurs.

Obviously the main question now concerns whether the strategies of proposition 7.15 correspond to player 1's worst SPE utility. The following theorem states an affirmative answer. Its proof is based upon the method of Shaked and Sutton, as introduced in section 3.4.1.

**Theorem 7.17.** For all $\delta \in [0, 1)$ it holds that the pair of SPE strategies in proposition 7.15 constitute player 1's pair of worst SPE strategies. Similar, the pair of SPE strategies in corollary 7.16 constitute player 1's pair of worst SPE strategies for all $\delta \in [0, 1)$. From this theorem a similar conclusion as at the end of section 7.2.2 can be drawn with respect to the results for bargaining procedure 7.8. Namely, theorem 7.17 reveals the implicit assumption that the strategies in the bargaining process underlying the modified variable-threat game in bargaining procedure 7.8 need to be Markov strategies. This implicit restriction to Markov strategies implies that disagreement actions are constant over time and have to be Nash equilibrium actions, that is, $a^t = a^N$, for all $t$ and $a^N \in A^N$. If the unspecified bargaining procedure is modelled as the alternating offers procedure, then richer SPE strategies emerge and a possibly larger set of SPE utility pairs arises.

### 7.3.4 The Set of SPE Utility Pairs

The upper and lower bounds upon the players' SPE utilities derived in theorem 7.17 enables us to characterize the set of SPE utilities, which is based upon the idea of equilibrium switching, as described in section 5.4.2. The discussion then continues by deriving sufficient and necessary conditions for generic uniqueness.

As said, the idea of equilibrium switching is employed to characterize the set of SPE utility pairs. This is accomplished by considering all SPE strategies that induce immediate agreement upon some possibly inefficient agreement. Equilibrium switching is already extensively discussed in section 5.4.2 and 5.4.3.

The strategies represented by table 7.3 can be considered as a straightforward translation of table 5.1 to the situation under consideration. The strategies start in state 'IA', where 'IA' stands for immediate agreement. In this initial state player 1 makes the possible inefficient proposal $s^* \in S$ that is accepted by his opponent. In case player 1 deviates by making a different proposal the strategies prescribe an immediate switch to the SPE strategies in proposition 7.15.

The latter strategies constitute player 1's most severe equilibrium punishment and, supposing acceptance by his opponent, this player will not deviate if and only if $s_1^* \geq x_1^*(\delta, (n_1, N_2))$. Similar, player 2 is deterred from rejecting the proposal $s^*$ if and only if $s_2^* \geq x_2^*(\delta, (N_1, n_2))$, because rejecting $s^*$ induces an immediate switch to player 2's most severe equilibrium punishment, i.e., the SPE strategies in proposition 7.16. Obviously, we have arrived at the following proposition, where $E_1(\delta) \subseteq S$ denotes the set of SPE utility pairs at the start of every even bargaining round.

**Proposition 7.18.** The strategies represented by table 7.3 are SPE strategies featuring immediate agreement upon $s^*$ at round $t = 0$ if and only if $s_1^* \geq x_1^*(\delta, (n_1, N_2))$ and $s_2^* \geq x_2^*(\delta, (N_1, n_2))$ for all $\delta \in [0, 1)$. Moreover, the history independent set of SPE utilities $E_1(\delta)$ at the start of every $t$ even is given by

$$E_1(\delta) = \left\{ s \in S \mid s_1 \geq x_1^*(\delta, (n_1, N_2)), \; s_2 \geq x_2^*(\delta, (N_1, n_2)) \right\}.$$

Note that this proposition is also valid in case the disagreement game admits a unique Nash equilibrium, i.e., $A^N$ consists of a single element, because then combining $(n_1, N_2) = (N_1, n_2) = d(a^N)$, $a^N \in A^N$, and the definition of the function $\mathbf{p} \times \mathbf{q}$ simply yields that $x_2^*(\delta, (N_1, n_2)) = x_2^*(\delta, (n_1, N_2))$. Thus, the upper and lower bounds coincide and the set $E_1(\delta)$ reduces to a single point on the Pareto frontier.

Without going through all the details, we mention that it is also straightforward to characterize the history independent set of SPE utility pairs at the subgame that coincides with the start of every odd numbered bargaining round. This set is given by

$$E_2(\delta) = \left\{ s \in S \mid s_1 \geq y_1^*(\delta, (n_1, N_2)), \; s_2 \geq y_2^*(\delta, (N_1, n_2)) \right\}.$$

Proposition 7.18 also makes it easy to characterize the limit set of SPE utility pairs. Then we obtain the following results, simply by taking the limit $\delta$ goes to 1.

**Theorem 7.19.** Let $E_j(\delta)$, $j = 1, 2$, denote the history independent set of SPE utilities for $\delta \in (0, 1)$ at the beginning of the bargaining round where player $j$ proposes. Then for $j = 1, 2$ it holds that

$$\lim_{\delta \to 1} E_j(\delta) = \left\{ s \in S \mid s_1 \geq N_1(S, (n_1, N_2)), \; s_2 \geq N_2(S, (N_1, n_2)) \right\},$$

where the function $N_i(\cdot)$, $i = 1, 2$, denotes player $i$'s utility according to the Nash bargaining solution.

We conclude this section with the derivation of conditions for uniqueness. For $\delta < 1$ this task is rather complicated, because conditions have to be specified under which a multiplicity of fixed points of the function $\mathbf{p} \times \mathbf{q}$ can be regarded as coinciding with each other. Since the Nash program is already identified with the limit $\delta$ goes to 1, we investigate the conditions for uniqueness in this limit, which is a case that is easy to handle.

Consider the limit set of theorem 7.19 once more. Obviously, uniqueness (in the limit) in bargaining procedure 7.11 simply requires that the two Nash bargaining solutions $N(S, (n_1, N_2))$ and $N(S, (N_1, n_2))$ coincide, i.e., $N(S, (n_1, N_2)) = N(S, (N_1, n_2))$.

In order to derive a condition for uniqueness we make use of the second geometrical property of the Nash bargaining solution, as discussed in section 4.2.2. For explanatory reasons we suppose that the Pareto frontier is smooth in the unique point, i.e., the function $f_1$ that describes this frontier is differentiable in $s_2 = n_2 = N_2$. Then uniqueness and the second geometrical property imply that the point $(N_1, n_2)$ should lie on the line through $(n_1, N_2)$ and $N(S, (n_1, N_2))$.$^5$ Of course, the latter condition trivially holds for the class of bargaining problems that admit a single Nash equilibrium in the disagreement game. However, outside this class of bargaining problems the condition for uniqueness is nongeneric, because slight changes in the players' utility functions are sufficient to shift $(N_1, n_2)$ off this line. This implies the following proposition.

**Proposition 7.20.** Consider the class of bargaining problems with a smooth Pareto frontier of $S$ in $N(S, d(a^N))$ for every $a^N \in A^N$. Then bargaining procedure 7.11 admits a unique SPE agreement if $A^N$ consists of a single element and it generically admits multiple SPE agreements otherwise.

So, this proposition states the same sufficient and almost necessary condition for uniqueness as in proposition 7.10, namely the set $A^N$ should consist of a unique Nash equilibrium. The latter means that the disagreement game rules out the coordination problem in case of multiple Nash equilibria. If a coordination problem over Nash equilibria arises, then this carries over to the negotiations.

Finally, for the case where the Pareto frontier of $S$ is not smooth in the point $N(S, d(a^N))$, $a^N \in A^N$, we refer to section 9.2.5. The results in the latter section can be easily translated into necessary and sufficient conditions for the nonsmooth case here.

### 7.3.5 SPE with Delay

Similar as in section 5.4.4 SPE strategies with delay can be supported in case the necessary and sufficient conditions for uniqueness, as stated in proposition 7.20 do not hold. Recall that the maximum equilibrium delay in section 5.4.4 is finite. Here a new feature may arise: Perpetual disagreement cannot be ruled out if some simple condition holds.

Since equilibrium strategies require that a Nash equilibrium is played in case of a breakdown we might as well start by considering some $a^N \in A^N$ and take this $a^N$ as the players' threats prescribed by the strategies. Recall that strategies also induce the intended round $t(\sigma)$ of agreement (delay means $t(\sigma) > 0$), the final agreement $s^{t(\sigma)}(\sigma) \in S$ at $t(\sigma)$ and the endogenous risk of breakdown $1 - \delta^{t(\sigma)}$. Then the associated utilities are given by $(1 - \delta^{t(\sigma)}) d(a^N) + \delta^{t(\sigma)} s^{t(\sigma)}(\sigma)$. The question is what are the equilibrium conditions upon $t(\sigma)$ and $s^{t(\sigma)}(\sigma) \in S$ such that these are SPE strategies. Similar as in section 5.4.4 we extend the strategies represented by table 7.3 by imposing a new initial state. In this initial state players must first make proposals until round $t(\sigma)$ that are rejected and we regard $(s_1^{Peff}, d_2)$ and $(d_1, s_2^{Peff})$ as natural candidates for these proposals, i.e., the proposing player demands his utopia utility in $S^P$ and is not willing to settle for anything less. In case player $j$, $j = 1, 2$, would make an offer that leaves less to himself than $s_j^{Peff}$, then equilibrium switching to this player's worst SPE is immediately triggered. At round $\bar{t}(s^*)$ the strategies move to state IA (immediate agreement) in table 7.3, including the same state transitions. These modified strategies implement the agreement $s^*$ at round $\bar{t}(s^*)$ and the players disagree until round $\bar{t}(s^*)$. Table 7.4 represents the initial state of the strategies that induce delay. Deriving equilibrium conditions upon $s^*$ and $\bar{t}(s^*)$ is similar as in the previous section and section 5.4.4 and therefore omitted.

**Proposition 7.21.** Let $a^N \in A^N$, $t(\sigma)$ be even and $s^* \in E_1(\delta)$. The strategies of table 7.4 are SPE if and only if

$$\left( 1 - \delta^{t(\sigma)} \right) d\left(a^N\right) + \delta^{t(\sigma)} s^* \geq \left( x_1^*(\delta, (n_1, N_2)), \; x_2^*(\delta, (N_1, n_2)) \right). \tag{7.6}$$

Note that in case of uniqueness we automatically have that $t(\sigma) = 0$ and $s^*$ coincides with the unique SPE outcome.

From equilibrium condition (7.6) the maximum delay of any SPE can be derived and for the details we refer once more to section 5.4.4. However, there is an interesting difference. With a fixed disagreement point the disagreement point is always located south-west of the point where both players are at their minimum SPE utility and this guarantees that the maximum delay has to be finite. Here, $d(a^N)$ corresponds to a Nash equilibrium utility pair and multiplicity of SPE outcome is definitely associated with multiple Nash equilibria in the disagreement game. Now, the following interesting case cannot be ruled out: The disagreement game may admit a Nash equilibrium $a^N \in A^N$ such that $d(a^N) \in E_1(\delta)$. Then for every $s^* \in E_1(\delta)$ and $t(\sigma) \in \mathbb{N}$ equilibrium condition (7.6) holds meaning that even $t(\sigma) = \infty$ can be supported by these SPE strategies. In this special case the negotiations break down with probability equal to 1 without the players reaching an agreement, i.e., perpetual disagreement.

**Corollary 7.22.** If there exists a pair of actions $a^N \in A^N$ such that $d(a^N) \in E_1(\delta)$, then for this particular $a^N$ and every $s^* \in E_1(\delta)$ equilibrium condition (7.6) imposes no maximum bound upon $t(\sigma)$. Moreover, for every $s^* \in E_1(\delta)$ there is one SPE strategy with perpetual disagreement.

The results obtained can be related to Thomas Schelling's point of view mentioned in the introduction of this chapter. If commitment fails the players' threats have to be credible. In case of multiple Nash equilibria there is an implicit struggle for coordination on one of these equilibria to obtain favourable bargaining positions. If the Nash equilibrium utilities lie relatively scattered, this struggle results in an indeterminacy and the possibility that this indeterminacy is never resolved and may cause bargaining impasses.

### 7.3.6 A Comparison Between Models

In this section the equilibrium outcomes of the two alternating offers procedures with and without commitment on threats are compared with each other.

This is done by first investigating the conditions under which these two models produce the same equilibrium conditions. For a short analysis we assume that the Pareto frontier of the bargaining problem is smooth.

Recall from section 7.2.2 that the bargaining procedure with commitment yields the unique outcome $N(S, (m_1, m_2))$. So, the question becomes when does the alternating offers procedure without commitment yield the same SPE outcome. First, the latter outcome has to be unique and for a smooth Pareto frontier this means that, genetically, the disagreement game may admit at most one Nash equilibrium. Second, the unique SPE outcome $N(S, d(a^N))$ has to coincide with $N(S, (m_1, m_2))$. Making use of the second geometrical property, this means that the unique Nash equilibrium utilities $d(a^N)$ have to lie on the line through $(m_1, m_2)$ and $N(S, (m_1, m_2))$ and this condition is relatively easy to check. This yields the following proposition.

**Proposition 7.23.** Let the Pareto frontier of $S$ be smooth in the point $s = N(S, (m_1, m_2))$. Then, in the limit as $\delta$ goes to 1, the set of SPE utility pairs of procedure 7.4 coincides with the limit set of procedure 7.11 if and only if the disagreement game admits a unique Nash equilibrium and the associated pair of Nash equilibrium utilities lie on the line piece with endpoints $(m_1, m_2)$ and $N(S, (m_1, m_2))$.

The necessary and sufficient conditions specify a generic class of bargaining problems that meet these conditions. This is easy to see if one realizes that the set $S$ need not be restricted at all for the class of (disagreement) games where the unique pair of Nash equilibrium utilities coincides with the players minmax levels. This is for example the case for the class of prisoners' dilemmas.

However, there is also a large class of bargaining problems, probably larger, for which these conditions are not met at all.

## 7.4 Numerical Examples

In this section two numerical examples are presented that illustrate the variety of results derived in this chapter. In the first example the players' threats correspond to the actions in the battle-of-the-sexes game. This example shows a multiplicity of SPE outcomes, including SPE outcomes featuring perpetual disagreement. The disagreement actions in the second example arise from the prisoners' dilemma. For this example all four bargaining procedures predict the same and unique agreement and the same threats

**Example 7.24.**

Consider the set $S = \{s \in \mathbb{R}^2_+ \mid s_1 + s_2 \leq 10\}$ and the battle of the sexes given by

|  | $L_2$ | $R_2$ |
|---|---|---|
| $L_1$ | 6, 2 | 0, 0 |
| $R_1$ | 0, 0 | 2, 6 |

The game admits three Nash equilibria, namely two pure given by $(L_1, L_2)$ and $(R_1, R_2)$ with corresponding utility pairs (6, 2) and (2, 6), and one in mixed strategies $(\sigma_1^*, \sigma_2^*) = ((\frac{3}{4}, \frac{1}{4}), (\frac{1}{4}, \frac{3}{4}))$ with expected utilities $(\frac{3}{2}, \frac{3}{2})$. Player $i$'s minmax value is given by $m_i = \frac{3}{2}$, $i = 1, 2$, and the corresponding minmax strategies coincide with the mixed Nash equilibrium.

Application of theorem 7.2 and example 7.3 to Nash's variable threat game implies that the equilibrium threats are found by solving the zero-sum game given by

|  | $L_2$ | $R_2$ |
|---|---|---|
| $L_1$ | 4, $-4$ | 0, 0 |
| $R_1$ | 0, 0 | $-4$, 4 |

and this game yields $(L_1, R_2)$ as the unique equilibrium threats. Note that these threats do not correspond to any of the three Nash equilibria of the battle of the sexes. The unique equilibrium agreement reached in the negotiations is given by $N(S, (0, 0)) = (5, 5)$. Note that the actions $(L_1, R_2)$ do not correspond to Nash equilibrium actions in the battle of the sexes and that commitment to these threats in case of a breakdown is necessary. Without commitment the players would have an incentive to deviate.

In case the alternating offers procedure replaces the demand game, as in procedure 7.4, the equilibrium threats change to the minmax actions, e.g., proposition 7.6. Here, the actions that minmax player $i$, $i = 1, 2$, coincide with the mixed Nash equilibrium. Thus, the players threaten each other with the mixed Nash equilibrium in case of a breakdown in every round and final agreement is $N(S, (\frac{3}{2}, \frac{3}{2})) = (5, 5)$ in the limit as $\delta$ goes to 1.

Procedure 7.8 describes Nash's variable threat game in the absence of an enforcement mechanism, i.e., players lack the ability to commit themselves prior to the negotiations. In that case, the players play one of the Nash equilibria in case of a breakdown, which means that there are three cases to consider. First, consider the SPE threats $(L_1, L_2)$. Then the SPE agreement is given by, with some abuse of notation, $N(S, (L_1, L_2)) = (7, 3)$. Second, reversal of the players roles yields $N(S, (R_1, R_2)) = (3, 7)$. Third, the results for the mixed Nash equilibrium case coincide with the results for the previous procedure. Which agreement actually results depends upon the self-fulfilling prophecy of which threats are anticipated by both players. Since the first two procedures always predict a unique equilibrium agreement, these results hint at that commitment plays an important role as some kind of coordination device.

Finally, consider procedure 7.11. Then the gap between a player's worst and best SPE agreement increases even further.

Proposition 7.15 implies that in, for example, player 1's worst SPE the threats are conditioned upon even and odd rounds. Here it is the threat of the actions $(R_1, L_2)$ in even rounds and the mixed Nash equilibrium in odd rounds. These yield the constructed disagreement point $(n_1, N_2) = (\frac{3}{2}, 6)$ with associated agreement $N(S, (n_1, N_2)) = (2\frac{1}{4}, 7\frac{3}{4})$. By symmetry, $(N_1, n_2) = (6, \frac{3}{2})$ with associated agreement $N(S, (N_1, n_2)) = (7\frac{3}{4}, 2\frac{1}{4})$. Theorem 7.19 then yields that the limit set of SPE utility pairs is given by

$$\left\{s \in \mathbb{R}^2_+ \mid s_1, s_2 \geq 2\tfrac{1}{4}, \; s_1 + s_2 \leq 10 \right\}.$$

This game is capable of generating perpetual disagreement, as described in corollary 7.22, provided we apply it to the correlated equilibrium in which $(L_1, L_2)$ and $(R_1, R_2)$ are equally probable.$^6$ Then the associated expected utility pair (4,4) lies in the limit set of payoffs and corollary 7.22 states that perpetual disagreement resulting in a breakdown and threats played according to this correlated equilibrium is a SPE outcome.

**Example 7.25.**

Consider $S = \{s \in \mathbb{R}^2_+ \mid s_1 + s_2 \leq 10\}$ and the prisoners' dilemma given by

|  | $L_2$ | $R_2$ |
|---|---|---|
| $L_1$ | 4, 4 | 0, 5 |
| $R_1$ | 5, 0 | 1, 1 |

The unique Nash equilibrium is $(R_1, R_2)$ and also constitutes the actions that minmax player $i$, $i = 1, 2$. This bargaining problem satisfies the necessary and sufficient conditions of proposition 7.23. To see this, first note that by theorem 7.2 and example 7.3 the equilibrium threats are found by solving the zero-sum game given by

|  | $L_2$ | $R_2$ |
|---|---|---|
| $L_1$ | 0, 0 | $-5$, 5 |
| $R_1$ | 5, $-5$ | 0, 0 |

and this game yields $(R_1, R_2)$ as the unique equilibrium threats with utility pair (1, 1) in the original prisoners' dilemma. The unique equilibrium agreement reached in Nash's variable threat game is given by $N(S, (1,1)) = (5, 5)$.

Then it is straightforward to see that for the prisoners' dilemma both bargaining procedure 7.4 and 7.11 yield the same (and unique) SPE agreement $N(S, (1, 1)) = (5, 5)$.

## 7.5 Related Literature

Nash's variable threat game is first analyzed in Nash (1953). This chapter is based upon Bolt and Houba (1998), where it was first suggested to replace the demand game by the alternating offers procedure. An analysis of Nash's variable threat game and its modified version without commitment can also be found in Van Damme (1991). In Mao (1993) the question is addressed whether or not players commit themselves if they have the freedom to do so and, in this reference it is shown that both players do commit themselves. This references is also the only reference that applies the $H$-essential equilibrium concept to the entire two-stage negotiation procedure, which is more appropriate then applying it to only the stage where the players play the demand game.

In this chapter the demand game is interpreted as the normal-form representation of some unspecified bargaining procedure. In Muthoo (1992) and (1996) another interesting point of view is proposed. In these papers the demand game is interpreted as a dynamic bargaining procedure with irrevocable commitments to the players' demands. As an alternative procedure a bargaining model is presented where commitments are revocable and where the players incur costs of revoking their commitments. In this way, a unifying framework is created in which Nash's demand game and the alternating offers procedure both fit.

In this chapter the notion of (non)commitment is strictly reserved to whether or not the players can commit to disagreement actions. In Fershtman and Seidmann (1993), Muthoo (1992) and (1996), it is argued that the alternating offers procedure can be regarded as a bargaining procedure where the players can make no commitments to their respective offers and in these references the standard model is modified in order to allow for 'partially' revocable commitments. Here, in these references, the disagreement point in the bargaining process is assumed to be fixed and exogenously given. Therefore, they restrict the notion of commitment to proposals and not to disagreement actions. Thus, in these models commitment is looked upon from a different angle.

## Notes

1. For an informal but entertaining treatment of the concept of commitment in situations of strategic interaction we refer to Dixit and Nalebuff (1991).
2. This is easy to see, because in case of a linear Pareto frontier, as in example 7.3, the equilibrium threats are the Nash equilibrium actions of a true zero-sum game and many of the early game-theoretic literature contains several examples that admit multiple Nash equilibria.
3. For example, consider the game $\Gamma$ as the $2 \times 2$ bimatrix game with each player's payoff matrix the 'identity' matrix $I_2$. According to example 7.3 the set of optimal threats is the complete set $A$, while theorem 7.7 predicts the unique equilibrium in symmetric mixed strategies.
4. The case for $f_1$ is not differentiable everywhere introduces a convex set of disagreement point that all yield the same Nash bargaining solution, as discussed in section 4.2.2. This case is left to the reader at this stage of the book. For the nondifferentiable case we also refer to section 9.2.5.
5. If $N(S, (n_1, N_2)) = N(S, (N_1, n_2))$ and the function $f_1$ is not differentiable in $s_2 = n_2 = N_2$ then the second geometrical property implies that the necessary and sufficient conditions for uniqueness are given by $(n_1, N_2), (N_1, n_2) \in D(s^*)$, $s^* = N(S, (N_1, n_2))$, where the set $D(s^*)$ is already defined in section 4.2.2. Rewriting the inequalities that characterize the set $D(s^*)$ yields less demanding conditions for uniqueness.
6. There is a notationally more demanding alternative approach: Condition the Nash equilibrium to be played upon even and odd rounds. For example, $(L_1, L_2)$ at an even round and $(R_1, R_2)$ at odd rounds. Then for sufficiently large $\delta < 1$ the same result can be obtained.
